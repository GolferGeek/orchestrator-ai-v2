# Local Development Environment Configuration
# Copy this to .env for local development

# ===== PORT CONFIGURATION =====
API_PORT=6100
WEB_PORT=7101
VITE_WEB_PORT=7101

# ===== SUPABASE LOCAL CONFIGURATION =====
# Local Supabase instance (started with `supabase start`)
SUPABASE_URL=http://127.0.0.1:54321
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU

# ===== VITE CONFIGURATION =====
VITE_API_BASE_URL=http://localhost:6100
VITE_API_NESTJS_BASE_URL=http://localhost:6100
VITE_SUPABASE_URL=http://127.0.0.1:54321
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0

# ===== OLLAMA CONFIGURATION =====
# Local Ollama (runs on your machine - no API key needed)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=

# Ollama Cloud (hosted service - requires API key)
# Get your API key at: https://ollama.com (sign up for free account)
# When OLLAMA_CLOUD_API_KEY is set, the system automatically uses cloud mode
# This is great for students/interns who don't have powerful local hardware!
OLLAMA_CLOUD_API_KEY=
OLLAMA_CLOUD_BASE_URL=https://ollama.com

# ===== AI MODEL CONFIGURATION =====
# Add your AI API keys here
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
PERPLEXITY_API_KEY=
GOOGLE_API_KEY=
MISTRAL_API_KEY=

# ===== LOGGING =====
LOG_LEVEL=debug
DEBUG_MEMORY_MANAGEMENT=false
DEBUG_MODEL_MONITORING=false

# ===== DEVELOPMENT SETTINGS =====
NODE_ENV=development
ENABLE_AUTO_MEMORY_OPTIMIZATION=true
ENABLE_MODEL_PRELOADING=false
ENABLE_HEALTH_MONITORING=true
PRELOAD_THREE_TIER_MODELS=false

# ===== MEMORY MANAGEMENT =====
MAX_MODEL_MEMORY_GB=8
MEMORY_PRESSURE_MEDIUM=0.6
MEMORY_PRESSURE_HIGH=0.8
MEMORY_PRESSURE_CRITICAL=0.95

# ===== ALERT THRESHOLDS (Development) =====
ALERT_RESPONSE_TIME_MS=15000
ALERT_ERROR_RATE=0.2
ALERT_MEMORY_USAGE=0.9
ALERT_UNAVAILABLE_TIME_MS=300000
ALERT_CONSECUTIVE_FAILURES=5

# ===== MONITORING INTERVALS =====
HEALTH_CHECK_INTERVAL_MS=120000
MEMORY_CHECK_INTERVAL_MS=60000
SYSTEM_CHECK_INTERVAL_MS=300000

# ===== PERFORMANCE TUNING =====
MODEL_LOAD_TIMEOUT_MS=300000
HEALTH_CHECK_TIMEOUT_MS=30000
HEALTH_CHECK_CACHE_MS=5000
MAX_CONCURRENT_LOADS=1

# ===== N8N CONFIGURATION (Development) =====
# n8n workflow automation - Development instance (port 7050)
GENERIC_TIMEZONE=America/Chicago
TZ=America/Chicago
N8N_PROTOCOL=http
N8N_DEV_ENCRYPTION_KEY=<generate-32-byte-base64-value>
N8N_DEV_DB_SCHEMA=n8n_dev

# ===== OBSERVABILITY CONFIGURATION =====
# Observability endpoint URL for sending webhook events
# Default: Uses API_PORT (6100) - observability endpoints are part of Orchestrator AI API
# Override if observability runs on a different port
OBSERVABILITY_SERVER_URL=http://localhost:6100

# ===== SECURITY (Development) =====
API_RATE_LIMIT=1000
ENABLE_API_AUTH=false
